{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shiwa\\Desktop\\mycode\\code5.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shiwa/Desktop/mycode/code5.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shiwa/Desktop/mycode/code5.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shiwa/Desktop/mycode/code5.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import skimage.io\n",
    "import os \n",
    "import tqdm\n",
    "import glob\n",
    "import tensorflow \n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage.color import grey2rgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shiwa\\Desktop\\mycode\\code5.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shiwa/Desktop/mycode/code5.ipynb#ch0000024?line=0'>1</a>\u001b[0m \u001b[39m# This Python 3 environment comes with many helpful analytics libraries installed\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shiwa/Desktop/mycode/code5.ipynb#ch0000024?line=1'>2</a>\u001b[0m \u001b[39m# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shiwa/Desktop/mycode/code5.ipynb#ch0000024?line=2'>3</a>\u001b[0m \u001b[39m# For example, here's several helpful packages to load\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shiwa/Desktop/mycode/code5.ipynb#ch0000024?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \u001b[39m# linear algebra\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shiwa/Desktop/mycode/code5.ipynb#ch0000024?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \u001b[39m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shiwa/Desktop/mycode/code5.ipynb#ch0000024?line=7'>8</a>\u001b[0m \u001b[39m# Input data files are available in the read-only \"../input/\" directory\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shiwa/Desktop/mycode/code5.ipynb#ch0000024?line=8'>9</a>\u001b[0m \u001b[39m# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   validation_split = 0.2,\n",
    "                                  \n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  validation_split = 0.2)\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale = 1./255\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset  = train_datagen.flow_from_directory(directory = '../mycode/Data/train',\n",
    "                                                   target_size = (224,224),\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = valid_datagen.flow_from_directory(directory = '../mycode/Data/valid',\n",
    "                                                  target_size = (224,224),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_datagen.flow_from_directory(directory = '../mycode/Data/test',\n",
    "                                                  target_size = (224,224),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(input_shape=(224,224,3),include_top=False,weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing Layers\n",
    "\n",
    "for layer in base_model.layers[:-8]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model\n",
    "\n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "plot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),  \n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "        f1_score,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 3,verbose = 1,factor = 0.50, min_lr = 1e-7)\n",
    "\n",
    "mcp = ModelCheckpoint('model.h5')\n",
    "\n",
    "es = EarlyStopping(verbose=1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "history=model.fit(train_dataset,validation_data=valid_dataset,epochs = 200,verbose = 1,callbacks=[lrd,mcp,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOTTING RESULTS (Train vs Validation FOLDER 1)\n",
    "\n",
    "def Train_Val_Plot(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,f1,val_f1):\n",
    "    \n",
    "    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))\n",
    "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "    ax1.plot(range(1, len(acc) + 1), acc)\n",
    "    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n",
    "    ax1.set_title('History of Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend(['training', 'validation'])\n",
    "\n",
    "\n",
    "    ax2.plot(range(1, len(loss) + 1), loss)\n",
    "    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n",
    "    ax2.set_title('History of Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(['training', 'validation'])\n",
    "    \n",
    "    ax3.plot(range(1, len(auc) + 1), auc)\n",
    "    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n",
    "    ax3.set_title('History of AUC')\n",
    "    ax3.set_xlabel('Epochs')\n",
    "    ax3.set_ylabel('AUC')\n",
    "    ax3.legend(['training', 'validation'])\n",
    "    \n",
    "    ax4.plot(range(1, len(precision) + 1), precision)\n",
    "    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n",
    "    ax4.set_title('History of Precision')\n",
    "    ax4.set_xlabel('Epochs')\n",
    "    ax4.set_ylabel('Precision')\n",
    "    ax4.legend(['training', 'validation'])\n",
    "    \n",
    "    ax5.plot(range(1, len(f1) + 1), f1)\n",
    "    ax5.plot(range(1, len(val_f1) + 1), val_f1)\n",
    "    ax5.set_title('History of F1-score')\n",
    "    ax5.set_xlabel('Epochs')\n",
    "    ax5.set_ylabel('F1 score')\n",
    "    ax5.legend(['training', 'validation'])\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "Train_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n",
    "               history.history['loss'],history.history['val_loss'],\n",
    "               history.history['auc'],history.history['val_auc'],\n",
    "               history.history['precision'],history.history['val_precision'],\n",
    "               history.history['f1_score'],history.history['val_f1_score']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        # Get the file from post request\n",
    "        f = request.files['file']\n",
    "\n",
    "        # Save the file to ./uploads\n",
    "        basepath = os.path.dirname(__file__)\n",
    "        file_path = os.path.join(\n",
    "            basepath, 'uploads', secure_filename(f.filename))\n",
    "        f.save(file_path)\n",
    "\n",
    "        # Make prediction\n",
    "        preds = model_predict(file_path, model)\n",
    "\n",
    "        # Process your result for human\n",
    "        # pred_class = preds.argmax(axis=-1)            # Simple argmax\n",
    "        pred_class = decode_predictions(preds, top=1)   # ImageNet Decode\n",
    "        result = str(pred_class[0][0][1])               # Convert to string\n",
    "        return result\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('lung')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c202ca8f89da73316f80f5a319bddb00938e69c620438b60fad3d339163153b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
